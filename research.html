<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Research â€“ S. T. Belen</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
<header>
  <div class="nav-container">
    <div class="logo">
      <a href="index.html">S. T. BELEN</a>
    </div>
    <nav>
      <a href="index.html#education">Education</a>
      <a href="index.html#experience">Experience</a>
      <a href="index.html#projects">Projects</a>
      <a href="index.html#ideas">Ideas</a>
      <a href="writings.html">Writings</a>
      <a href="research.html">Research</a>
      <a href="index.html#contact">Contact</a>
    </nav>
  </div>
</header>

<main>
  <section id="research">
    <h1>Research</h1>
    <p class="page-subtitle">
      Papers and books Iâ€™m reading or have really spent time with â€“ mostly around RL, control,
      and optimization.
    </p>

    <div class="grid">
      <article class="card">
        <h2>Reading List</h2>
        <p class="meta">ML, RL, optimization, and linear algebra</p>

        <!-- OKUDUKLARIM -->
        <h3 style="margin-top:0.6rem;">OkuduklarÄ±m</h3>
        <ul class="list">
          <li>
            <strong>Convex Optimization (Stephen Boyd &amp; Lieven Vandenberghe)</strong><br />
            Modern optimization rehberi gibi: hangi problemin neden konveks olduÄŸunu, geometrik
            olarak ne ifade ettiÄŸini ve pratikte buna nasÄ±l algoritma tasarladÄ±ÄŸÄ±mÄ±zÄ± Ã§ok net
            anlatÄ±yor. Bence ML, kontrol ve sinyal iÅŸleme tarafÄ±nÄ± birleÅŸtiren temel kitaplardan.
          </li>

          <li>
            <strong>Introduction to Applied Linear Algebra (Boyd &amp; Vandenberghe)</strong><br />
            VektÃ¶rler, matrisler ve least squaresâ€™i hem teorik hem de â€œbunu koda nasÄ±l dÃ¶kerim?â€
            bakÄ±ÅŸÄ±yla veriyor. Ders notu gibi temiz; mÃ¼hendislik Ã¶ÄŸrencisi iÃ§in tam kÃ¶prÃ¼ kitap.
          </li>

          <li>
            <strong>Proximal Policy Optimization Algorithms (Schulman et al., 2017)</strong><br />
            PPOâ€™yu tanÄ±tan makale. Politika gradyanlarÄ±nÄ± Ã§ok karmaÅŸÄ±k hale getirmeden, â€œclippingâ€
            fikriyle gÃ¼ncellemeleri stabil tutuyor. Rolout topla, birkaÃ§ epoch clipped update yap
            ve iyi sonuÃ§ al â€“ pratik RL iÃ§in gÃ¼zel bir temel reÃ§ete.
          </li>

          <li>
            <strong>Domain Randomization for Transferring Deep Neural Networks from Simulation
              to the Real World (Tobin et al., 2017)</strong><br />
            SimÃ¼lasyonu mÃ¼kemmel gerÃ§ekÃ§i yapmak yerine, ortamÄ± bilinÃ§li olarak rastgeleleÅŸtirip
            aÄŸÄ± dayanÄ±klÄ± hale getirme fikri. Ã–zellikle robotik algÄ± tarafÄ±nda sim-to-real boÅŸluÄŸunu
            kapatmak iÃ§in hoÅŸ, mÃ¼hendislik odaklÄ± bir yaklaÅŸÄ±m.
          </li>
        </ul>

        <!-- OKUMAKTA OLDUKLARIM -->
        <h3 style="margin-top:1.1rem;">Okumakta olduklarÄ±m</h3>
        <ul class="list">
          <li>
            <strong>Reinforcement Learning: An Introduction (Sutton &amp; Barto)</strong><br />
            Åu an yavaÅŸ yavaÅŸ sindirerek gidiyorum. DÃ¶nÃ¼ÅŸler, deÄŸer fonksiyonlarÄ±, TD Ã¶ÄŸrenme
            gibi kavramlarÄ± Ã§ok adÄ±m adÄ±m kuruyor; not Ã§Ä±kararak okuduÄŸum bir kitap. Deep RL
            tarafÄ±na geÃ§meden Ã¶nce temel sezgiyi oturtmak iÃ§in birebir.
          </li>

          <li>
            <strong>Multi-Agent Reinforcement Learning: Foundations and Modern Approaches</strong><br />
            Bunu da parÃ§a parÃ§a okuyorum. Tek ajan RLâ€™den Ã§ok ajanlÄ± dÃ¼nyaya geÃ§iÅŸi â€” iÅŸbirliÄŸi,
            rekabet, oyun kuramÄ± ve modern deep RL teknikleriyle birlikte â€” gÃ¼zel Ã§erÃ§eveliyor.
            HenÃ¼z bitirmedim ama Ã¶zellikle multi-agent kontrol / robotik iÃ§in ufuk aÃ§Ä±cÄ± duruyor.
          </li>
        </ul>

        <!-- TAVSÄ°YE ETTÄ°KLERÄ°M -->
        <h3 style="margin-top:1.1rem;">Tavsiye ettiklerim</h3>
        <ul class="list">
          <li>
            <strong>BaÅŸlangÄ±Ã§ hattÄ±:</strong> 
            <em>Introduction to Applied Linear Algebra</em> ile lineer cebiri saÄŸlamlaÅŸtÄ±rÄ±p,
            ardÄ±ndan <em>Convex Optimization</em> ile optimizasyon bakÄ±ÅŸ aÃ§Ä±sÄ±nÄ± oturtmak;
            sonrasÄ±nda da <em>Reinforcement Learning: An Introduction</em> ile RL dÃ¼nyasÄ±na
            girmek, benim iÃ§in en mantÄ±klÄ± ve zevkli yol oldu/oluyor.
          </li>
          <li>
            <strong>RL tarafÄ±nda derinleÅŸmek isteyen iÃ§in:</strong>
            PPO makalesi (Schulman et al.) pratik policy gradient dÃ¼nyasÄ±na yumuÅŸak bir giriÅŸ,
            devamÄ±nda ise okudukÃ§a <em>Multi-Agent Reinforcement Learning: Foundations and Modern Approaches</em>
            Ã§ok ajanlÄ± senaryolar iÃ§in gÃ¼zel bir vizyon veriyor.
          </li>
        </ul>
      </article>
    </div>
  </section>

  <section id="contact" style="margin-top:3rem;">
    <h2>Contact</h2>
    <ul class="contact-list">
      <li>ğŸ“§ Email: <a href="mailto:talha.belen@ug.bilkent.edu.tr">talha.belen@ug.bilkent.edu.tr</a></li>
      <li>ğŸ“Œ LinkedIn: <a href="https://www.linkedin.com/in/suleyman-talha-belen-b0645a2a5" target="_blank" rel="noopener">suleyman-talha-belen</a></li>
      <li>ğŸ™ GitHub: <a href="https://github.com/stalhabelen" target="_blank" rel="noopener">stalhabelen</a></li>
    </ul>
  </section>
</main>

<footer>
  <span>Â© <span id="year"></span> S. T. Belen</span>
  <span class="back-to-top" onclick="window.scrollTo({ top: 0, behavior: 'smooth' });">
    Back to top â†‘
  </span>
</footer>

<script>
  document.getElementById("year").textContent = new Date().getFullYear();
</script>
</body>
</html>